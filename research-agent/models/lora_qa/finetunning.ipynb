{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73bda8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Generate a multiple-choice question from the following context.', 'input': 'Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.', 'output': \"Question: What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?\\nOptions: ['coriolis effect', 'muon effect', 'centrifugal effect', 'tropical effect']\\nCorrect: coriolis effect\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.jsonl\")[\"train\"]\n",
    "print(train_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec2134c-eb64-44a7-a6cc-a7dfc5f3a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from trl) (1.10.1)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from trl) (4.56.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from accelerate>=1.4.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from accelerate>=1.4.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=1.4.0->trl) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=1.4.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from accelerate>=1.4.0->trl) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from accelerate>=1.4.0->trl) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2024.7.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets>=3.0.0->trl) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.56.1->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\raunak\\anaconda3\\envs\\ai_tutor\\lib\\site-packages (from transformers>=4.56.1->trl) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raunak\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Downloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 564.7/564.7 kB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install trl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbd7b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c108eb2f8ea4aea9e096741bb507b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raunak\\anaconda3\\envs\\ai_tutor\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raunak\\.cache\\huggingface\\hub\\models--HuggingFaceH4--zephyr-7b-beta. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceH4/zephyr-7b-beta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token  \u001b[38;5;66;03m# fix padding issue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_tutor\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1125\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1124\u001b[0m         )\n\u001b[1;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_tutor\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2142\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 2142\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_tutor\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2128\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         failed\u001b[38;5;241m.\u001b[39mappend(msg\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 2128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # fix padding issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600e327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
