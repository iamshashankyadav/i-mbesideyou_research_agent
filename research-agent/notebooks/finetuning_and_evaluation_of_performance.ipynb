{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "88fccea2fc5c4d059697a9d963ae4a36",
            "2916799eb9314ceab9e71ed210d57f7a",
            "95040c8eca004027b215d39f0c5b2a8f",
            "ece6f3330af745ed85473bea9416598e",
            "f6827e0779a44f75b606d0abae3b2673",
            "9649b128bd3d4c6b9635f20867df7fe1",
            "06c7856220f745c6b1796d71227882c2",
            "8fecfa739c844e4f82f095e6daa948f2",
            "59160750ef8d4288bbbe7c7fcf5bb03c",
            "5d707f2b057442ef901bc3da92fdbe04",
            "59ae9fd7e1a7410292e364953df46549",
            "abec8059707f4e08b376860290405b8d",
            "cbe17b52d6604ee8820a0d4ad3ce8166",
            "38e6c9ccdf954aa3bb99b1d1fcf17e3b",
            "e40fa8b771e4455588210942f0dbdc98",
            "c235d35a07d448d69e1a563e168b7e5a",
            "90c9a85f56444d69b0dd48bd572d9e30",
            "cbabc9ef93ca4c148e8645b1d69771bd",
            "31c50c4db4c34135af08f58cfebf6dfc",
            "c8c69cb7465e441c9a592d2c6cf7428a",
            "af510f19364a4be4acaa83f26cf390e8",
            "98b6c764f92444d48c2fde0fa0c9746d"
          ]
        },
        "id": "1DrYq4583GRR",
        "outputId": "6f16c0d3-8063-4b17-e525-23a502c43ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting QLoRA training pipeline...\n",
            "üîß Loading model: microsoft/Phi-3-mini-4k-instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88fccea2fc5c4d059697a9d963ae4a36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Model setup complete:\n",
            "trainable params: 4,456,448 || all params: 3,825,536,000 || trainable%: 0.1165\n",
            "üìÇ Loading data from train_dataset.jsonl (max 2000 samples)...\n",
            "‚úÖ Loaded 2000 examples (limited from 2000)\n",
            "\n",
            "üìã Sample formatted text:\n",
            "<|system|>\n",
            "You are a scientific question generator. Create clear, accurate multiple-choice questions from scientific text.\n",
            "\n",
            "<|user|>\n",
            "Generate a multiple-choice question from the following context.\n",
            "\n",
            "Context: Mesophiles grow best in moderate temperature, typically between 25¬∞C and 40¬∞C (77¬∞F and 104¬∞F...\n",
            "üî§ Tokenizing 2000 texts...\n",
            "üìä Dataset created with 2000 examples\n",
            "üìè Average length: 201.3 tokens\n",
            "üéØ Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-992834368.py:193: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='110' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [110/125 21:44 < 03:01, 0.08 it/s, Epoch 0.87/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.728600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.967500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.946600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.943300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 25:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.728600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.967500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.946600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.943300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving adapter...\n",
            "\n",
            "üìã Saved files:\n",
            "   added_tokens.json: 0.00 MB\n",
            "   README.md: 0.00 MB\n",
            "   adapter_config.json: 0.00 MB\n",
            "   adapter_model.safetensors: 17.02 MB\n",
            "   special_tokens_map.json: 0.00 MB\n",
            "   tokenizer.model: 0.48 MB\n",
            "   tokenizer.json: 3.45 MB\n",
            "   tokenizer_config.json: 0.00 MB\n",
            "   chat_template.jinja: 0.00 MB\n",
            "‚úÖ Training completed! Adapter saved to: ./qa_adapter\n",
            "üß™ Testing trained model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abec8059707f4e08b376860290405b8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Testing failed: 'DynamicCache' object has no attribute 'seen_tokens'\n",
            "\n",
            "üéâ Success! Your adapter is ready at: ./qa_adapter\n",
            "üì¶ You can now use this adapter in your agent!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:2412: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import os\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "\n",
        "# Disable wandb\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "def create_bnb_config():\n",
        "    \"\"\"4-bit quantization config for T4 GPU\"\"\"\n",
        "    return BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "def create_lora_config():\n",
        "    \"\"\"LoRA configuration\"\"\"\n",
        "    return LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def format_qa_prompt(item):\n",
        "    \"\"\"Format the training data into prompt format\"\"\"\n",
        "    return f\"\"\"<|system|>\n",
        "You are a scientific question generator. Create clear, accurate multiple-choice questions from scientific text.\n",
        "\n",
        "<|user|>\n",
        "{item[\"instruction\"]}\n",
        "\n",
        "Context: {item[\"input\"]}\n",
        "\n",
        "<|assistant|>\n",
        "{item[\"output\"]}<|end|>\"\"\"\n",
        "\n",
        "def load_and_format_data(jsonl_file, max_samples=2000):  # Limit to 2000 samples\n",
        "    \"\"\"Load JSONL and format prompts - with sample limit for fast training\"\"\"\n",
        "    formatted_texts = []\n",
        "\n",
        "    print(f\"üìÇ Loading data from {jsonl_file} (max {max_samples} samples)...\")\n",
        "    with open(jsonl_file, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if len(formatted_texts) >= max_samples:  # Stop at limit\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                item = json.loads(line.strip())\n",
        "                formatted_text = format_qa_prompt(item)\n",
        "                formatted_texts.append(formatted_text)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"‚ö†Ô∏è  Skipping invalid JSON on line {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(formatted_texts)} examples (limited from {max_samples})\")\n",
        "\n",
        "    # Show sample\n",
        "    if formatted_texts:\n",
        "        print(\"\\nüìã Sample formatted text:\")\n",
        "        print(formatted_texts[0][:300] + \"...\" if len(formatted_texts[0]) > 300 else formatted_texts[0])\n",
        "\n",
        "    return formatted_texts\n",
        "\n",
        "def create_dataset(texts, tokenizer, max_length=512):\n",
        "    \"\"\"Create and tokenize dataset - DON'T manually add labels\"\"\"\n",
        "\n",
        "    print(f\"üî§ Tokenizing {len(texts)} texts...\")\n",
        "\n",
        "    # Tokenize all texts at once - NO MANUAL LABELS\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=False,  # Don't pad yet - let DataCollator do it\n",
        "        max_length=max_length,\n",
        "        return_overflowing_tokens=False,\n",
        "        return_length=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Create dataset WITHOUT labels - DataCollatorForLanguageModeling will handle this\n",
        "    dataset = Dataset.from_dict({\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"],\n",
        "        # NO \"labels\" key - let the collator create them automatically\n",
        "    })\n",
        "\n",
        "    print(f\"üìä Dataset created with {len(dataset)} examples\")\n",
        "    print(f\"üìè Average length: {sum(len(ids) for ids in encodings['input_ids']) / len(encodings['input_ids']):.1f} tokens\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def setup_model_and_tokenizer(model_name=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
        "    \"\"\"Setup 4-bit quantized model with LoRA\"\"\"\n",
        "\n",
        "    print(f\"üîß Loading model: {model_name}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Load model with quantization\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=create_bnb_config(),\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"eager\"  # Avoid flash attention issues\n",
        "    )\n",
        "\n",
        "    # Prepare for k-bit training\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # Add LoRA\n",
        "    lora_config = create_lora_config()\n",
        "    model = get_peft_model(model, lora_config)\n",
        "\n",
        "    print(\"üéØ Model setup complete:\")\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def create_training_args(output_dir=\"./qa_adapter\", num_epochs=1):  # Reduced from 3 to 1\n",
        "    \"\"\"Create training arguments optimized for fast training\"\"\"\n",
        "    return TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=num_epochs,  # 1 epoch instead of 3\n",
        "        per_device_train_batch_size=8,  # Increased from 2 to 8\n",
        "        gradient_accumulation_steps=2,  # Reduced from 4 to 2\n",
        "        warmup_steps=25,  # Reduced from 50\n",
        "        logging_steps=20,  # Less frequent logging\n",
        "        save_steps=1000,  # Less frequent saves\n",
        "        learning_rate=5e-4,  # Higher learning rate for faster convergence\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        optim=\"adamw_torch\",\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_pin_memory=False,\n",
        "        gradient_checkpointing=True,\n",
        "        max_grad_norm=1.0,\n",
        "        report_to=[],  # Disable wandb\n",
        "        save_strategy=\"epoch\",  # Save only at end\n",
        "        load_best_model_at_end=False,\n",
        "        dataloader_num_workers=0,  # Avoid multiprocessing overhead\n",
        "    )\n",
        "\n",
        "\n",
        "def train_qlora_model(jsonl_file, output_dir=\"./qa_adapter\", model_name=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "\n",
        "    try:\n",
        "        # 1. Setup model and tokenizer\n",
        "        print(\"üöÄ Starting QLoRA training pipeline...\")\n",
        "        model, tokenizer = setup_model_and_tokenizer(model_name)\n",
        "\n",
        "        # 2. Load and format data (limited samples)\n",
        "        texts = load_and_format_data(jsonl_file, max_samples=2000)  # Only 2000 samples\n",
        "        if not texts:\n",
        "            raise ValueError(\"No valid data found in JSONL file\")\n",
        "\n",
        "        # 3. Create dataset\n",
        "        dataset = create_dataset(texts, tokenizer)\n",
        "\n",
        "        # 4. Setup training\n",
        "        training_args = create_training_args(output_dir)\n",
        "\n",
        "        # 5. Data collator (handles padding dynamically)\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=tokenizer,\n",
        "            mlm=False,  # We're doing causal LM, not masked LM\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # 6. Create trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=dataset,\n",
        "            data_collator=data_collator,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "\n",
        "        # 7. Train\n",
        "        print(\"üéØ Starting training...\")\n",
        "        trainer.train()\n",
        "\n",
        "        # 8. Save model\n",
        "        print(\"üíæ Saving adapter...\")\n",
        "        model.save_pretrained(output_dir)\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Check file sizes\n",
        "        print(\"\\nüìã Saved files:\")\n",
        "        for filename in os.listdir(output_dir):\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            if os.path.isfile(filepath):\n",
        "                size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "                print(f\"   {filename}: {size_mb:.2f} MB\")\n",
        "\n",
        "        print(f\"‚úÖ Training completed! Adapter saved to: {output_dir}\")\n",
        "        return output_dir\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def test_trained_model(adapter_path, test_context=None):\n",
        "    \"\"\"Test the trained model\"\"\"\n",
        "\n",
        "    if test_context is None:\n",
        "        test_context = \"\"\"\n",
        "        Photosynthesis is the process by which plants convert light energy into chemical energy.\n",
        "        During this process, carbon dioxide and water are converted into glucose and oxygen\n",
        "        using energy from sunlight. This process occurs in the chloroplasts of plant cells.\n",
        "        \"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\"üß™ Testing trained model...\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(adapter_path, trust_remote_code=True)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        # Load base model\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "            quantization_config=create_bnb_config(),\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Load with adapter\n",
        "        from peft import PeftModel\n",
        "        model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "\n",
        "        # Create test prompt\n",
        "        prompt = f\"\"\"<|system|>\n",
        "You are a scientific question generator. Create clear, accurate multiple-choice questions from scientific text.\n",
        "\n",
        "<|user|>\n",
        "Generate a multiple-choice question from the following context.\n",
        "\n",
        "Context: {test_context}\n",
        "\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "        # Generate\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs,\n",
        "                max_new_tokens=200,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated = response.split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "        print(\"üéâ Generated Question:\")\n",
        "        print(generated)\n",
        "\n",
        "        return generated\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Testing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Usage example\n",
        "def main():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "\n",
        "    # Set your JSONL file path\n",
        "    JSONL_FILE = \"train_dataset.jsonl\"  # Update this path\n",
        "    OUTPUT_DIR = \"./qa_adapter\"\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(JSONL_FILE):\n",
        "        print(f\"‚ùå File not found: {JSONL_FILE}\")\n",
        "        print(\"Please upload your JSONL file to Colab first!\")\n",
        "        return\n",
        "\n",
        "    # Train the model\n",
        "    adapter_path = train_qlora_model(JSONL_FILE, OUTPUT_DIR)\n",
        "\n",
        "    if adapter_path:\n",
        "        # Test the model\n",
        "        test_trained_model(adapter_path)\n",
        "\n",
        "        print(f\"\\nüéâ Success! Your adapter is ready at: {adapter_path}\")\n",
        "        print(\"üì¶ You can now use this adapter in your agent!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8j33oFb4a8q",
        "outputId": "8aa75bb4-f508-496f-f2d5-2a2f0aa30968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: transformers 4.56.1\n",
            "Uninstalling transformers-4.56.1:\n",
            "  Successfully uninstalled transformers-4.56.1\n",
            "Found existing installation: accelerate 1.10.1\n",
            "Uninstalling accelerate-1.10.1:\n",
            "  Successfully uninstalled accelerate-1.10.1\n",
            "Found existing installation: peft 0.17.1\n",
            "Uninstalling peft-0.17.1:\n",
            "  Successfully uninstalled peft-0.17.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Force reinstall everything\n",
        "!pip uninstall -y bitsandbytes transformers accelerate peft\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "gqRRl10m4l1Y"
      },
      "outputs": [],
      "source": [
        "# Install specific compatible versions\n",
        "!pip install bitsandbytes>=0.42.0\n",
        "!pip install transformers>=4.36.0\n",
        "!pip install peft>=0.7.0\n",
        "!pip install accelerate>=0.25.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hfh6zZvGbIA"
      },
      "source": [
        "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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJRSVNXT5zQW",
        "outputId": "45481ddd-7763-4721-d59b-4270285a7a2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:bitsandbytes.cextension:The 8-bit optimizer is not available on your device, only available on CUDA for now.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ BitsAndBytes working!\n",
            "Version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Test if it works\n",
        "try:\n",
        "    from transformers import BitsAndBytesConfig\n",
        "    import bitsandbytes as bnb\n",
        "    print(\"‚úÖ BitsAndBytes working!\")\n",
        "    print(f\"Version: {bnb.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Still not working: {e}\")\n",
        "    print(\"Use fallback method below...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JatjCsU6lTw",
        "outputId": "fb60fea1-28b7-48d6-febf-2b5f56416b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Sep 16 04:32:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "GPU: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Memory: 15.8 GB\n",
            "BF16 Support: False\n"
          ]
        }
      ],
      "source": [
        "# Run this to check your GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Check PyTorch CUDA capability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU: {gpu_props.name}\")\n",
        "    print(f\"Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
        "    print(f\"Memory: {gpu_props.total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "    # Check bf16 support (needs compute capability >= 8.0)\n",
        "    supports_bf16 = gpu_props.major >= 8\n",
        "    print(f\"BF16 Support: {supports_bf16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2570235c9a884840bc1345c3922835f0",
            "d3c09c55fbe2475999305c494a9e5f86",
            "d5969279042d45fab6c8dfbf87202cf4",
            "5e2491325bfd4179a2a81840c453fb48",
            "6991bf455dc84fd5bba5369f000f78e0",
            "cc86e9b1134645e5878de82698b5adae",
            "6a065a5dd9f944379b762d6f61f451b0",
            "64cd0a1737a44c848284a71cb8a1d7ea",
            "115edd570640483b94f3623707e6dff3",
            "4b77f8a1e1ee40a7833cf13744de682a",
            "e4a6560f9d5a45deb91aecc3835253f3"
          ]
        },
        "id": "oluG00nhy12f",
        "outputId": "b6f28693-2636-4172-a67d-6b79acc0d1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Simple Adapter Tester\n",
            "==================================================\n",
            "üìä System Info:\n",
            "üì¶ Transformers version: 4.56.1\n",
            "üî• PyTorch version: 2.8.0+cu126\n",
            "‚ö° CUDA available: True\n",
            "üéÆ GPU: Tesla T4\n",
            "üíæ GPU Memory: 15.8 GB\n",
            "\n",
            "üß™ Testing adapter...\n",
            "üîÑ Loading adapter for testing...\n",
            "üîß Attempting to load Phi-3 model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2570235c9a884840bc1345c3922835f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Error loading model: 'base_model.model.model.lm_head'\n",
            "üîÑ Trying alternative approach...\n",
            "üîÑ Using alternative testing method...\n",
            "üìÅ Adapter files found: ['added_tokens.json', 'README.md', 'checkpoint-125', 'adapter_config.json', 'adapter_model.safetensors', 'special_tokens_map.json', 'tokenizer.model', 'tokenizer.json', 'tokenizer_config.json', 'chat_template.jinja']\n",
            "‚úÖ Adapter files look good!\n",
            "üìã Adapter configuration:\n",
            "   Task type: CAUSAL_LM\n",
            "   Rank (r): 8\n",
            "   Alpha: 16\n",
            "   Target modules: ['up_proj', 'v_proj', 'k_proj', 'gate_proj', 'o_proj', 'down_proj', 'q_proj']\n",
            "   added_tokens.json: 0.00 MB\n",
            "   README.md: 0.00 MB\n",
            "   adapter_config.json: 0.00 MB\n",
            "   adapter_model.safetensors: 17.02 MB\n",
            "   special_tokens_map.json: 0.00 MB\n",
            "   tokenizer.model: 0.48 MB\n",
            "   tokenizer.json: 3.45 MB\n",
            "   tokenizer_config.json: 0.00 MB\n",
            "   chat_template.jinja: 0.00 MB\n",
            "üì¶ Total adapter size: 20.96 MB\n",
            "\n",
            "üéØ Adapter appears to be trained successfully!\n",
            "üîß The model loading issue is likely due to transformers version compatibility.\n",
            "üí° Your adapter is ready to use in your main agent code!\n",
            "\n",
            "üéâ Testing completed successfully!\n",
            "\n",
            "üîß Here's how to integrate into your agent:\n",
            "üîß Agent Integration Code:\n",
            "\n",
            "# Integration code for your agent system\n",
            "class ScientificQAGenerator:\n",
            "    def __init__(self, adapter_path=\"./qa_adapter\"):\n",
            "        self.adapter_path = adapter_path\n",
            "        self.model = None\n",
            "        self.tokenizer = None\n",
            "        self.loaded = False\n",
            "    \n",
            "    def load_model(self):\n",
            "        \"\"\"Load model when needed\"\"\"\n",
            "        if self.loaded:\n",
            "            return\n",
            "            \n",
            "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
            "        from peft import PeftModel\n",
            "        \n",
            "        # Load tokenizer\n",
            "        self.tokenizer = AutoTokenizer.from_pretrained(self.adapter_path)\n",
            "        if self.tokenizer.pad_token is None:\n",
            "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
            "        \n",
            "        # Load base model (adjust based on your needs)\n",
            "        base_model = AutoModelForCausalLM.from_pretrained(\n",
            "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
            "            torch_dtype=torch.float16,\n",
            "            device_map=\"auto\"\n",
            "        )\n",
            "        \n",
            "        # Load with adapter\n",
            "        self.model = PeftModel.from_pretrained(base_model, self.adapter_path)\n",
            "        self.loaded = True\n",
            "    \n",
            "    def generate_questions(self, scientific_text, num_questions=1):\n",
            "        \"\"\"Generate questions from scientific text\"\"\"\n",
            "        if not self.loaded:\n",
            "            self.load_model()\n",
            "        \n",
            "        questions = []\n",
            "        for _ in range(num_questions):\n",
            "            prompt = f\"Generate a multiple-choice question from: {scientific_text}\"\n",
            "            \n",
            "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
            "            outputs = self.model.generate(inputs, max_length=200, do_sample=True)\n",
            "            question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
            "            questions.append(question)\n",
            "        \n",
            "        return questions\n",
            "    \n",
            "    def cleanup(self):\n",
            "        \"\"\"Free memory\"\"\"\n",
            "        if self.model:\n",
            "            del self.model\n",
            "            del self.tokenizer\n",
            "            torch.cuda.empty_cache()\n",
            "        self.loaded = False\n",
            "\n",
            "# Usage in your agent:\n",
            "# qa_generator = ScientificQAGenerator(\"./qa_adapter\")\n",
            "# questions = qa_generator.generate_questions(\"Your scientific text here\")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def simple_test_adapter(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Simplified adapter test that avoids compatibility issues\"\"\"\n",
        "\n",
        "    print(\"üîÑ Loading adapter for testing...\")\n",
        "\n",
        "    try:\n",
        "        # Method 1: Try with original model\n",
        "        print(\"üîß Attempting to load Phi-3 model...\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(adapter_path, trust_remote_code=True)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        # Load base model without quantization first (for compatibility)\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            attn_implementation=\"eager\"\n",
        "        )\n",
        "\n",
        "        # Load adapter\n",
        "        model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "\n",
        "        print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "        print(\"üîÑ Trying alternative approach...\")\n",
        "        return test_adapter_alternative(adapter_path)\n",
        "\n",
        "    # Test context\n",
        "    test_context = \"\"\"\n",
        "    Photosynthesis is the process by which plants convert light energy into chemical energy.\n",
        "    During this process, carbon dioxide and water are converted into glucose and oxygen\n",
        "    using energy from sunlight. This process occurs in the chloroplasts of plant cells.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create simple prompt\n",
        "    prompt = f\"\"\"Generate a multiple-choice question from the following context.\n",
        "\n",
        "Context: {test_context}\n",
        "\n",
        "Question:\"\"\"\n",
        "\n",
        "    print(\"üß™ Testing question generation...\")\n",
        "\n",
        "    try:\n",
        "        # Tokenize\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        # Generate with minimal settings to avoid issues\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs,\n",
        "                max_length=inputs.shape[1] + 150,  # Use max_length instead of max_new_tokens\n",
        "                temperature=0.8,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                num_return_sequences=1,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        question = generated_text[len(prompt):].strip()\n",
        "\n",
        "        print(\"‚úÖ Generated Question:\")\n",
        "        print(question)\n",
        "\n",
        "        # Cleanup\n",
        "        del model\n",
        "        del base_model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Generation failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_adapter_alternative(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Alternative test using direct adapter files\"\"\"\n",
        "\n",
        "    print(\"üîÑ Using alternative testing method...\")\n",
        "\n",
        "    try:\n",
        "        # Check if adapter files exist\n",
        "        import os\n",
        "        adapter_files = os.listdir(adapter_path)\n",
        "        print(f\"üìÅ Adapter files found: {adapter_files}\")\n",
        "\n",
        "        # Just verify the adapter was saved correctly\n",
        "        required_files = [\"adapter_config.json\"]\n",
        "        missing_files = [f for f in required_files if f not in adapter_files]\n",
        "\n",
        "        if missing_files:\n",
        "            print(f\"‚ùå Missing adapter files: {missing_files}\")\n",
        "            return False\n",
        "\n",
        "        print(\"‚úÖ Adapter files look good!\")\n",
        "\n",
        "        # Read adapter config to verify\n",
        "        import json\n",
        "        with open(os.path.join(adapter_path, \"adapter_config.json\"), 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        print(f\"üìã Adapter configuration:\")\n",
        "        print(f\"   Task type: {config.get('task_type')}\")\n",
        "        print(f\"   Rank (r): {config.get('r')}\")\n",
        "        print(f\"   Alpha: {config.get('lora_alpha')}\")\n",
        "        print(f\"   Target modules: {config.get('target_modules')}\")\n",
        "\n",
        "        # Calculate adapter size\n",
        "        total_size = 0\n",
        "        for file in adapter_files:\n",
        "            file_path = os.path.join(adapter_path, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                size = os.path.getsize(file_path)\n",
        "                total_size += size\n",
        "                print(f\"   {file}: {size / (1024*1024):.2f} MB\")\n",
        "\n",
        "        print(f\"üì¶ Total adapter size: {total_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "        # Simple functionality test without loading the full model\n",
        "        print(\"\\nüéØ Adapter appears to be trained successfully!\")\n",
        "        print(\"üîß The model loading issue is likely due to transformers version compatibility.\")\n",
        "        print(\"üí° Your adapter is ready to use in your main agent code!\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Alternative test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def quick_model_info():\n",
        "    \"\"\"Quick check of model compatibility\"\"\"\n",
        "    try:\n",
        "        import transformers\n",
        "        print(f\"üì¶ Transformers version: {transformers.__version__}\")\n",
        "\n",
        "        import torch\n",
        "        print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "        print(f\"‚ö° CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"üéÆ GPU: {torch.cuda.get_device_name()}\")\n",
        "            print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error checking system info: {e}\")\n",
        "        return False\n",
        "\n",
        "# Integration code for your agent\n",
        "def create_agent_qa_generator(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Code to integrate into your main agent\"\"\"\n",
        "\n",
        "    code_template = f'''\n",
        "# Integration code for your agent system\n",
        "class ScientificQAGenerator:\n",
        "    def __init__(self, adapter_path=\"{adapter_path}\"):\n",
        "        self.adapter_path = adapter_path\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.loaded = False\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load model when needed\"\"\"\n",
        "        if self.loaded:\n",
        "            return\n",
        "\n",
        "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "        from peft import PeftModel\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.adapter_path)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load base model (adjust based on your needs)\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        # Load with adapter\n",
        "        self.model = PeftModel.from_pretrained(base_model, self.adapter_path)\n",
        "        self.loaded = True\n",
        "\n",
        "    def generate_questions(self, scientific_text, num_questions=1):\n",
        "        \"\"\"Generate questions from scientific text\"\"\"\n",
        "        if not self.loaded:\n",
        "            self.load_model()\n",
        "\n",
        "        questions = []\n",
        "        for _ in range(num_questions):\n",
        "            prompt = f\"Generate a multiple-choice question from: {{scientific_text}}\"\n",
        "\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(inputs, max_length=200, do_sample=True)\n",
        "            question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            questions.append(question)\n",
        "\n",
        "        return questions\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Free memory\"\"\"\n",
        "        if self.model:\n",
        "            del self.model\n",
        "            del self.tokenizer\n",
        "            torch.cuda.empty_cache()\n",
        "        self.loaded = False\n",
        "\n",
        "# Usage in your agent:\n",
        "# qa_generator = ScientificQAGenerator(\"{adapter_path}\")\n",
        "# questions = qa_generator.generate_questions(\"Your scientific text here\")\n",
        "'''\n",
        "\n",
        "    print(\"üîß Agent Integration Code:\")\n",
        "    print(code_template)\n",
        "\n",
        "    return code_template\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üéØ Simple Adapter Tester\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check system info\n",
        "    print(\"üìä System Info:\")\n",
        "    quick_model_info()\n",
        "    print()\n",
        "\n",
        "    # Test the adapter\n",
        "    print(\"üß™ Testing adapter...\")\n",
        "    success = simple_test_adapter(\"./qa_adapter\")\n",
        "\n",
        "    if success:\n",
        "        print(\"\\nüéâ Testing completed successfully!\")\n",
        "        print(\"\\nüîß Here's how to integrate into your agent:\")\n",
        "        create_agent_qa_generator(\"./qa_adapter\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  Testing had issues, but your adapter is likely still good!\")\n",
        "        print(\"üí° The compatibility issue is with the testing code, not your trained adapter.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "65ee94d5a7954fe287320a0171958995",
            "20cb6a5b52094396a0bbb7600c514212",
            "1490ec9b6d3e49729ababf4f8739a72f",
            "bf05f7f9b67a4923930331b7d1fc4d18",
            "cd81a28e38d04d7b80bc67d86f2b7f43",
            "4d3dcf659176403fae3d3c7d316337a0",
            "ce82056d330646d99deb461345e18fc7",
            "a485cab7043d46858fa60f6aff28cc14",
            "663ca508975c4310925a4c6cdc44a661",
            "566284d195c040a9aaf1021386df8995",
            "d2a858f323664438b70a513d5414d0a5"
          ]
        },
        "id": "DqIIdZFJWoVq",
        "outputId": "a265d46a-e44c-467a-ffaa-26860d445749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ QA Generator Adapter Tester\n",
            "==================================================\n",
            "\n",
            "1Ô∏è‚É£ Running quick test...\n",
            "üîÑ Loading model with adapter from ./qa_adapter...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65ee94d5a7954fe287320a0171958995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded successfully!\n",
            "üöÄ Quick Test:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Question:\n",
            "e eukaryotic cell to divide into two identical nuclei?\n",
            "Options: ['mitosis', 'cytokinesis', 'apoptosis', 'meiosis']\n",
            "Correct: mitosis\n",
            "üßπ Memory cleaned up!\n",
            "\n",
            "‚úÖ Testing completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import PeftModel\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def create_bnb_config():\n",
        "    \"\"\"4-bit quantization config\"\"\"\n",
        "    return BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "class QAGeneratorTester:\n",
        "    \"\"\"Test your trained QA generator adapter\"\"\"\n",
        "\n",
        "    def __init__(self, adapter_path=\"./qa_adapter\", base_model=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
        "        self.adapter_path = adapter_path\n",
        "        self.base_model = base_model\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load base model with adapter\"\"\"\n",
        "        print(f\"üîÑ Loading model with adapter from {self.adapter_path}...\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.adapter_path, trust_remote_code=True)\n",
        "\n",
        "        # Fix tokenizer issues\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        # Load base model with 4-bit quantization\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            quantization_config=create_bnb_config(),\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16,\n",
        "            trust_remote_code=True,\n",
        "            attn_implementation=\"eager\"  # Avoid attention issues\n",
        "        )\n",
        "\n",
        "        # Load with adapter\n",
        "        self.model = PeftModel.from_pretrained(base_model, self.adapter_path)\n",
        "        print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    def generate_question(self, context, max_new_tokens=200, temperature=0.7):\n",
        "        \"\"\"Generate a scientific question from context\"\"\"\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = f\"\"\"<|system|>\n",
        "You are a scientific question generator. Create clear, accurate multiple-choice questions from scientific text.\n",
        "\n",
        "<|user|>\n",
        "Generate a multiple-choice question from the following context.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "        # Tokenize and ensure proper device placement\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Move to correct device\n",
        "        device = next(self.model.parameters()).device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Generate with proper settings - avoid cache issues\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                use_cache=False,  # Disable cache to avoid compatibility issues\n",
        "                return_dict_in_generate=False\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract just the assistant's response\n",
        "        if \"<|assistant|>\" in full_response:\n",
        "            generated_question = full_response.split(\"<|assistant|>\")[-1].strip()\n",
        "        else:\n",
        "            generated_question = full_response[len(prompt):].strip()\n",
        "\n",
        "        return generated_question\n",
        "\n",
        "    def test_multiple_contexts(self):\n",
        "        \"\"\"Test with multiple scientific contexts\"\"\"\n",
        "\n",
        "        test_contexts = [\n",
        "            # Biology\n",
        "            \"\"\"\n",
        "            Photosynthesis is the process by which plants convert light energy into chemical energy.\n",
        "            During this process, carbon dioxide and water are converted into glucose and oxygen\n",
        "            using energy from sunlight. This process occurs in the chloroplasts of plant cells.\n",
        "            \"\"\",\n",
        "\n",
        "            # Chemistry\n",
        "            \"\"\"\n",
        "            Catalysts are substances that increase the rate of chemical reactions without being\n",
        "            consumed in the process. They work by providing an alternative reaction pathway with\n",
        "            lower activation energy. Enzymes are biological catalysts that are highly specific\n",
        "            for particular reactions.\n",
        "            \"\"\",\n",
        "\n",
        "            # Physics\n",
        "            \"\"\"\n",
        "            Newton's first law of motion states that an object at rest stays at rest and an object\n",
        "            in motion stays in motion with the same speed and in the same direction unless acted\n",
        "            upon by an unbalanced force. This is also known as the law of inertia.\n",
        "            \"\"\",\n",
        "\n",
        "            # Medicine\n",
        "            \"\"\"\n",
        "            Antibiotics are medicines that fight bacterial infections in people and animals. They work\n",
        "            by killing bacteria or making it difficult for bacteria to grow and multiply. However,\n",
        "            antibiotics do not work against viral infections such as the common cold or flu.\n",
        "            \"\"\"\n",
        "        ]\n",
        "\n",
        "        print(\"üß™ Testing with multiple scientific contexts...\\n\")\n",
        "\n",
        "        for i, context in enumerate(test_contexts, 1):\n",
        "            print(f\"üìù Test {i}:\")\n",
        "            print(f\"Context: {context.strip()[:100]}...\")\n",
        "\n",
        "            try:\n",
        "                question = self.generate_question(context)\n",
        "                print(f\"‚úÖ Generated Question:\\n{question}\\n\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error generating question: {e}\\n\")\n",
        "\n",
        "        print(\"üéâ Testing completed!\")\n",
        "\n",
        "    def interactive_test(self):\n",
        "        \"\"\"Interactive testing - input your own context\"\"\"\n",
        "        print(\"üéÆ Interactive Testing Mode\")\n",
        "        print(\"Enter scientific text to generate questions (or 'quit' to exit):\\n\")\n",
        "\n",
        "        while True:\n",
        "            context = input(\"üìù Enter scientific context: \").strip()\n",
        "\n",
        "            if context.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"üëã Goodbye!\")\n",
        "                break\n",
        "\n",
        "            if not context:\n",
        "                print(\"‚ö†Ô∏è  Please enter some text!\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                question = self.generate_question(context)\n",
        "                print(f\"\\nü§ñ Generated Question:\\n{question}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error: {e}\\n\")\n",
        "\n",
        "    def benchmark_generation_speed(self, num_tests=5):\n",
        "        \"\"\"Test generation speed\"\"\"\n",
        "        import time\n",
        "\n",
        "        test_context = \"\"\"\n",
        "        DNA replication is the process by which a double-stranded DNA molecule is copied\n",
        "        to produce two identical DNA molecules. This process is essential for cell division\n",
        "        and occurs in the S phase of the cell cycle.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"‚è±Ô∏è  Testing generation speed ({num_tests} runs)...\")\n",
        "\n",
        "        times = []\n",
        "        for i in range(num_tests):\n",
        "            start_time = time.time()\n",
        "            question = self.generate_question(test_context)\n",
        "            end_time = time.time()\n",
        "\n",
        "            generation_time = end_time - start_time\n",
        "            times.append(generation_time)\n",
        "            print(f\"Run {i+1}: {generation_time:.2f}s\")\n",
        "\n",
        "        avg_time = sum(times) / len(times)\n",
        "        print(f\"\\nüìä Average generation time: {avg_time:.2f}s\")\n",
        "        print(f\"üìä Tokens per second estimate: ~{200/avg_time:.1f}\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Free up GPU memory\"\"\"\n",
        "        del self.model\n",
        "        del self.tokenizer\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"üßπ Memory cleaned up!\")\n",
        "\n",
        "# Usage functions\n",
        "def quick_test(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Quick test of your adapter\"\"\"\n",
        "    tester = QAGeneratorTester(adapter_path)\n",
        "\n",
        "    # Test with a simple context\n",
        "    context = \"\"\"\n",
        "    Mitosis is a type of cell division that results in two daughter cells each having\n",
        "    the same number and kind of chromosomes as the parent nucleus. It is essential\n",
        "    for growth and repair in multicellular organisms.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ Quick Test:\")\n",
        "    question = tester.generate_question(context)\n",
        "    print(f\"Generated Question:\\n{question}\")\n",
        "\n",
        "    return tester\n",
        "\n",
        "def comprehensive_test(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Comprehensive testing\"\"\"\n",
        "    tester = QAGeneratorTester(adapter_path)\n",
        "\n",
        "    # Run multiple tests\n",
        "    tester.test_multiple_contexts()\n",
        "\n",
        "    # Speed benchmark\n",
        "    tester.benchmark_generation_speed(3)\n",
        "\n",
        "    return tester\n",
        "\n",
        "def interactive_mode(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Interactive testing mode\"\"\"\n",
        "    tester = QAGeneratorTester(adapter_path)\n",
        "    tester.interactive_test()\n",
        "    return tester\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üéØ QA Generator Adapter Tester\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Choose your test mode:\n",
        "\n",
        "    # Option 1: Quick test\n",
        "    print(\"\\n1Ô∏è‚É£ Running quick test...\")\n",
        "    tester = quick_test(\"./qa_adapter\")\n",
        "\n",
        "    # Option 2: Comprehensive test (uncomment to run)\n",
        "    # print(\"\\n2Ô∏è‚É£ Running comprehensive test...\")\n",
        "    # tester = comprehensive_test()\n",
        "\n",
        "    # Option 3: Interactive mode (uncomment to run)\n",
        "    # print(\"\\n3Ô∏è‚É£ Starting interactive mode...\")\n",
        "    # tester = interactive_mode()\n",
        "\n",
        "    # Cleanup\n",
        "    tester.cleanup()\n",
        "\n",
        "    print(\"\\n‚úÖ Testing completed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813,
          "referenced_widgets": [
            "0d517f8043b148f2bd3d5950dc80c946",
            "bda4596e37c04c21a678cda292d637e2",
            "25f220c3e53746e7b0bd16696e9d8b62",
            "630d56bd42d44f42ad1f5f095f127134",
            "2c26a737d6ca43feb88214d30da65c59",
            "e77b67394cfb4c0a9fbcd3114e606a8f",
            "c31252560d3c48dd8f59c3576c373688",
            "ccb2ee2abbe04334afb2ae2a9173c4a2",
            "ad88bf875792445ca477093e1db8ccdc",
            "14a900a1d3184631960a2d4b01146186",
            "d61c3c9d668c428c9688f050e31b0c71",
            "23522d8efbb8467d8a5343e44d81c778",
            "8026095f28ed453db681ca6b5a3e6004",
            "00d66d35cd254b7db98101bf637ffce8",
            "61ccc0ee45474932b0638719a3c02139",
            "45da3481df8e4ec3abea2a98820b3fcc",
            "357fdca8035b4a0691b35552029ff3ba",
            "4596a4bd71ee4939bc907a2ffc099f0f",
            "783fd5f9e0d34590af17adac73659370",
            "b715f7dc07bf42f683d21ee1a3d5a5de",
            "3df5fddc48764fd1bad393616d6d606a",
            "1ffbd396dc0e43929bc62d7987c46e74",
            "d2ab2131b87c4216a924994dee4c9429",
            "a40545f45b9344ee9ee3906d2dada0fc",
            "4a75c000baba4409a82d95ee97a8fa17",
            "855902b5c55047389f37c1ec9b5fac57",
            "e63f066a983e4a74b82b22fbfcca43da",
            "3798554d15f744e1bf60c61a42e3d4b0",
            "3d8349737b744266afbf8e850a6d21ff",
            "0ecb7806bb08455ab41f6206147107c6",
            "2c0c7e57edc94a3583cb2a86ec26b07b",
            "7f359a1daafc4e1c98e3cdd10d0be765",
            "d008e5dc094444f68c23b9c028bf4610",
            "451660d2ba1e4b1fa592acfb14b8471c",
            "bd964c8bcfd946fda06506d3b33d032c",
            "233696c261e147ecae7a927bf149d551",
            "cc1801f7329245659141d66e838b66e4",
            "4e78a6457b94498986253dd19a3b309d",
            "e7144f441e8a4b47b5c76f53d294ad4a",
            "742a4cf56eb34cb98ef1c46e5bc8de67",
            "8377e2a71204448290a5fc7bf60c9b43",
            "1c6a3776c7204a9ca876aead451aa85b",
            "afedd9773fa441c68345adf6811b8091",
            "50d864059afb4af58d40ad07051770d8",
            "14a248b3132344ef8d0faa2423b61648",
            "b914549f08a648c69d1536dd4c43b41e",
            "14f0b15eac474d52ae18a28b449d1824",
            "8de6b6f1f8c44dcdbabf4044ead2cdc6",
            "55c469002fe14c7bba14a4571fae8c45",
            "dbd6a5133fec4493992edb587ef7fb81",
            "a5750dc15a0e498d9737738d88a9ec34",
            "dfe17b73ab9c45c3a861b8239d75b25d",
            "7ade09eaf0bd414983365a4d81b630fc",
            "b551b38d0461487595126e8bdbb3d98e",
            "198540889a5a4a7db55ef7227306567f",
            "aa85516d59e14b5db849fa58003b794a",
            "03a39a3a8ba748458b3497462579e477",
            "c45b9f6b58384adfbe14e3033c26f31d",
            "6ba02fb49e024339b353c4bfa60c4c66",
            "1c69587c0b624aaebd05aaabbbeb92e6",
            "949b0a01f54e43a2a33f16ace68ba63a",
            "ba12d5e58ac14494baccf7b456082bd9",
            "8b3a61cb55c240569f2f6a376a97476d",
            "9ab23decda9642cdbb906896582b853b",
            "a5ce804418e04a76b0603145b0efc2c9",
            "7f81fc8579684b209ea5253a895f3bdb"
          ]
        },
        "id": "iw2S7MzQb8DJ",
        "outputId": "7566a6f0-a8f3-4f12-8a34-35fb3798dd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ QA Generator Evaluation System\n",
            "============================================================\n",
            "Choose evaluation mode:\n",
            "1. Full evaluation (10 contexts)\n",
            "2. Quick evaluation (3 contexts)\n",
            "Enter choice (1/2): 2\n",
            "‚ö° Quick Evaluation Mode\n",
            "========================================\n",
            "üîÑ Loading model with adapter from ./qa_adapter...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d517f8043b148f2bd3d5950dc80c946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23522d8efbb8467d8a5343e44d81c778",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2ab2131b87c4216a924994dee4c9429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "451660d2ba1e4b1fa592acfb14b8471c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14a248b3132344ef8d0faa2423b61648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa85516d59e14b5db849fa58003b794a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded successfully!\n",
            "\n",
            "üìù Quick Test 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Score: 49.2/100 (Poor)\n",
            "   Question: does photosynthesis produce?\n",
            "Options: ['glucose', 'carbohydrate', 'protein', 'li...\n",
            "\n",
            "üìù Quick Test 2:\n",
            "   Score: 49.4/100 (Poor)\n",
            "   Question: oth strands serve in the formation of?\n",
            "Options: ['complementary', 'identical cop...\n",
            "\n",
            "üìù Quick Test 3:\n",
            "   Score: 47.0/100 (Poor)\n",
            "   Question: n do you have to take if your body is infected with an uncontrollable virus?\n",
            "Opt...\n",
            "üßπ Memory cleaned up!\n",
            "\n",
            "‚úÖ Evaluation completed!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import PeftModel\n",
        "import warnings\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def create_bnb_config():\n",
        "    \"\"\"4-bit quantization config\"\"\"\n",
        "    return BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "class QAEvaluationMetrics:\n",
        "    \"\"\"Comprehensive evaluation metrics for QA generation quality\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics = defaultdict(list)\n",
        "        self.detailed_results = []\n",
        "\n",
        "    def evaluate_question_structure(self, question):\n",
        "        \"\"\"Evaluate the structural quality of a generated question\"\"\"\n",
        "        score = 0\n",
        "        issues = []\n",
        "\n",
        "        # Check if it contains a question\n",
        "        if '?' in question or 'Question:' in question:\n",
        "            score += 20\n",
        "        else:\n",
        "            issues.append(\"No question mark or question indicator found\")\n",
        "\n",
        "        # Check for multiple choice options\n",
        "        if any(indicator in question.lower() for indicator in ['options:', 'a)', 'b)', 'c)', 'd)', '1.', '2.', '3.', '4.']):\n",
        "            score += 25\n",
        "        else:\n",
        "            issues.append(\"No multiple choice options detected\")\n",
        "\n",
        "        # Check for correct answer indication\n",
        "        if any(indicator in question.lower() for indicator in ['correct:', 'answer:', 'correct answer']):\n",
        "            score += 20\n",
        "        else:\n",
        "            issues.append(\"No correct answer indication\")\n",
        "\n",
        "        # Check reasonable length (not too short, not too long)\n",
        "        if 50 <= len(question) <= 500:\n",
        "            score += 15\n",
        "        else:\n",
        "            issues.append(f\"Unusual length: {len(question)} characters\")\n",
        "\n",
        "        # Check for scientific terminology\n",
        "        scientific_terms = ['process', 'system', 'energy', 'cell', 'molecule', 'reaction', 'function', 'structure', 'mechanism']\n",
        "        if any(term in question.lower() for term in scientific_terms):\n",
        "            score += 10\n",
        "\n",
        "        # Check for coherence (no repeated phrases)\n",
        "        words = question.lower().split()\n",
        "        if len(words) == len(set(words)):\n",
        "            score += 10\n",
        "        else:\n",
        "            issues.append(\"Contains repeated words/phrases\")\n",
        "\n",
        "        return min(score, 100), issues\n",
        "\n",
        "    def evaluate_relevance(self, context, question):\n",
        "        \"\"\"Evaluate how relevant the question is to the context\"\"\"\n",
        "        score = 0\n",
        "\n",
        "        # Extract key terms from context\n",
        "        context_words = set(context.lower().split())\n",
        "        question_words = set(question.lower().split())\n",
        "\n",
        "        # Calculate word overlap\n",
        "        common_words = context_words.intersection(question_words)\n",
        "        if common_words:\n",
        "            overlap_ratio = len(common_words) / max(len(context_words), len(question_words))\n",
        "            score += min(overlap_ratio * 100, 40)\n",
        "\n",
        "        # Check if question asks about main concepts from context\n",
        "        # Extract potential key concepts (capitalized words, scientific terms)\n",
        "        context_concepts = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[a-z]+)*\\b', context)\n",
        "        concept_mentioned = any(concept.lower() in question.lower() for concept in context_concepts)\n",
        "        if concept_mentioned:\n",
        "            score += 30\n",
        "\n",
        "        # Check if question is answerable from context\n",
        "        # This is a simplified heuristic\n",
        "        if len(common_words) >= 3:\n",
        "            score += 30\n",
        "\n",
        "        return min(score, 100)\n",
        "\n",
        "    def evaluate_difficulty_level(self, question):\n",
        "        \"\"\"Evaluate the cognitive difficulty level of the question\"\"\"\n",
        "\n",
        "        # Bloom's taxonomy indicators\n",
        "        remembering_words = ['what', 'when', 'where', 'which', 'who', 'define', 'list', 'name']\n",
        "        understanding_words = ['explain', 'describe', 'compare', 'contrast', 'summarize']\n",
        "        applying_words = ['apply', 'demonstrate', 'solve', 'use', 'calculate']\n",
        "        analyzing_words = ['analyze', 'examine', 'investigate', 'categorize', 'differentiate']\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        if any(word in question_lower for word in analyzing_words):\n",
        "            return \"High (Analyzing)\", 4\n",
        "        elif any(word in question_lower for word in applying_words):\n",
        "            return \"Medium-High (Applying)\", 3\n",
        "        elif any(word in question_lower for word in understanding_words):\n",
        "            return \"Medium (Understanding)\", 2\n",
        "        elif any(word in question_lower for word in remembering_words):\n",
        "            return \"Low (Remembering)\", 1\n",
        "        else:\n",
        "            return \"Unknown\", 0\n",
        "\n",
        "    def evaluate_scientific_accuracy(self, context, question):\n",
        "        \"\"\"Evaluate if the question maintains scientific accuracy\"\"\"\n",
        "        score = 100  # Start with perfect score and deduct\n",
        "        issues = []\n",
        "\n",
        "        # Check for scientific terminology consistency\n",
        "        scientific_terms_context = re.findall(r'\\b[a-z]*(?:ology|osis|tion|ism|ase|ide|ine)\\b', context.lower())\n",
        "        scientific_terms_question = re.findall(r'\\b[a-z]*(?:ology|osis|tion|ism|ase|ide|ine)\\b', question.lower())\n",
        "\n",
        "        # Check if question introduces terms not in context\n",
        "        question_terms = set(scientific_terms_question)\n",
        "        context_terms = set(scientific_terms_context)\n",
        "\n",
        "        introduced_terms = question_terms - context_terms\n",
        "        if len(introduced_terms) > 2:\n",
        "            score -= 20\n",
        "            issues.append(f\"Introduces new scientific terms: {introduced_terms}\")\n",
        "\n",
        "        # Check for contradictions (simplified)\n",
        "        negation_words = ['not', 'never', 'no', 'without', 'exclude']\n",
        "        if any(word in question.lower() for word in negation_words):\n",
        "            # This requires more sophisticated logic, simplified for now\n",
        "            pass\n",
        "\n",
        "        return max(score, 0), issues\n",
        "\n",
        "    def calculate_readability_score(self, text):\n",
        "        \"\"\"Calculate simplified readability score\"\"\"\n",
        "        sentences = text.split('.')\n",
        "        words = text.split()\n",
        "\n",
        "        if len(sentences) == 0 or len(words) == 0:\n",
        "            return 0\n",
        "\n",
        "        avg_sentence_length = len(words) / max(len(sentences), 1)\n",
        "\n",
        "        # Simplified readability (lower is more readable)\n",
        "        if avg_sentence_length <= 10:\n",
        "            return \"High (Easy to read)\"\n",
        "        elif avg_sentence_length <= 20:\n",
        "            return \"Medium (Moderately easy)\"\n",
        "        else:\n",
        "            return \"Low (Complex)\"\n",
        "\n",
        "    def evaluate_single_question(self, context, question, expected_answer=None):\n",
        "        \"\"\"Comprehensive evaluation of a single question\"\"\"\n",
        "\n",
        "        result = {\n",
        "            'context': context[:100] + \"...\",\n",
        "            'question': question,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "\n",
        "        # Structure evaluation\n",
        "        structure_score, structure_issues = self.evaluate_question_structure(question)\n",
        "        result['structure_score'] = structure_score\n",
        "        result['structure_issues'] = structure_issues\n",
        "\n",
        "        # Relevance evaluation\n",
        "        relevance_score = self.evaluate_relevance(context, question)\n",
        "        result['relevance_score'] = relevance_score\n",
        "\n",
        "        # Difficulty evaluation\n",
        "        difficulty_level, difficulty_numeric = self.evaluate_difficulty_level(question)\n",
        "        result['difficulty_level'] = difficulty_level\n",
        "        result['difficulty_numeric'] = difficulty_numeric\n",
        "\n",
        "        # Scientific accuracy evaluation\n",
        "        accuracy_score, accuracy_issues = self.evaluate_scientific_accuracy(context, question)\n",
        "        result['accuracy_score'] = accuracy_score\n",
        "        result['accuracy_issues'] = accuracy_issues\n",
        "\n",
        "        # Readability evaluation\n",
        "        readability = self.calculate_readability_score(question)\n",
        "        result['readability'] = readability\n",
        "\n",
        "        # Overall score calculation (weighted average)\n",
        "        overall_score = (\n",
        "            structure_score * 0.3 +\n",
        "            relevance_score * 0.3 +\n",
        "            accuracy_score * 0.2 +\n",
        "            min(difficulty_numeric * 25, 100) * 0.2\n",
        "        )\n",
        "        result['overall_score'] = overall_score\n",
        "\n",
        "        # Quality rating\n",
        "        if overall_score >= 85:\n",
        "            result['quality_rating'] = \"Excellent\"\n",
        "        elif overall_score >= 70:\n",
        "            result['quality_rating'] = \"Good\"\n",
        "        elif overall_score >= 50:\n",
        "            result['quality_rating'] = \"Fair\"\n",
        "        else:\n",
        "            result['quality_rating'] = \"Poor\"\n",
        "\n",
        "        self.detailed_results.append(result)\n",
        "        return result\n",
        "\n",
        "    def get_summary_statistics(self):\n",
        "        \"\"\"Get summary statistics from all evaluations\"\"\"\n",
        "        if not self.detailed_results:\n",
        "            return \"No evaluations performed yet\"\n",
        "\n",
        "        # Extract scores\n",
        "        structure_scores = [r['structure_score'] for r in self.detailed_results]\n",
        "        relevance_scores = [r['relevance_score'] for r in self.detailed_results]\n",
        "        accuracy_scores = [r['accuracy_score'] for r in self.detailed_results]\n",
        "        overall_scores = [r['overall_score'] for r in self.detailed_results]\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'total_questions': len(self.detailed_results),\n",
        "            'average_scores': {\n",
        "                'structure': np.mean(structure_scores),\n",
        "                'relevance': np.mean(relevance_scores),\n",
        "                'accuracy': np.mean(accuracy_scores),\n",
        "                'overall': np.mean(overall_scores)\n",
        "            },\n",
        "            'score_ranges': {\n",
        "                'structure': (min(structure_scores), max(structure_scores)),\n",
        "                'relevance': (min(relevance_scores), max(relevance_scores)),\n",
        "                'accuracy': (min(accuracy_scores), max(accuracy_scores)),\n",
        "                'overall': (min(overall_scores), max(overall_scores))\n",
        "            },\n",
        "            'quality_distribution': {}\n",
        "        }\n",
        "\n",
        "        # Quality distribution\n",
        "        quality_counts = defaultdict(int)\n",
        "        for result in self.detailed_results:\n",
        "            quality_counts[result['quality_rating']] += 1\n",
        "        stats['quality_distribution'] = dict(quality_counts)\n",
        "\n",
        "        return stats\n",
        "\n",
        "class QAGeneratorEvaluator:\n",
        "    \"\"\"Enhanced QA Generator with comprehensive evaluation capabilities\"\"\"\n",
        "\n",
        "    def __init__(self, adapter_path=\"./qa_adapter\", base_model=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
        "        self.adapter_path = adapter_path\n",
        "        self.base_model = base_model\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.evaluator = QAEvaluationMetrics()\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load base model with adapter\"\"\"\n",
        "        print(f\"üîÑ Loading model with adapter from {self.adapter_path}...\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.adapter_path, trust_remote_code=True)\n",
        "\n",
        "        # Fix tokenizer issues\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        # Load base model with 4-bit quantization\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            quantization_config=create_bnb_config(),\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16,\n",
        "            trust_remote_code=True,\n",
        "            attn_implementation=\"eager\"\n",
        "        )\n",
        "\n",
        "        # Load with adapter\n",
        "        self.model = PeftModel.from_pretrained(base_model, self.adapter_path)\n",
        "        print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    def generate_question(self, context, max_new_tokens=200, temperature=0.7):\n",
        "        \"\"\"Generate a scientific question from context\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"<|system|>\n",
        "You are a scientific question generator. Create clear, accurate multiple-choice questions from scientific text.\n",
        "\n",
        "<|user|>\n",
        "Generate a multiple-choice question from the following context.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "        # Tokenize and ensure proper device placement\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Move to correct device\n",
        "        device = next(self.model.parameters()).device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Generate with proper settings\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                use_cache=False,\n",
        "                return_dict_in_generate=False\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract just the assistant's response\n",
        "        if \"<|assistant|>\" in full_response:\n",
        "            generated_question = full_response.split(\"<|assistant|>\")[-1].strip()\n",
        "        else:\n",
        "            generated_question = full_response[len(prompt):].strip()\n",
        "\n",
        "        return generated_question\n",
        "\n",
        "    def evaluate_comprehensive_test(self):\n",
        "        \"\"\"Run comprehensive evaluation with diverse scientific contexts\"\"\"\n",
        "\n",
        "        # Expanded test contexts covering various scientific domains\n",
        "        test_contexts = [\n",
        "            # Biology - Cell Biology\n",
        "            \"\"\"\n",
        "            Photosynthesis is the process by which plants convert light energy into chemical energy.\n",
        "            During this process, carbon dioxide and water are converted into glucose and oxygen\n",
        "            using energy from sunlight. This process occurs in the chloroplasts of plant cells.\n",
        "            \"\"\",\n",
        "\n",
        "            # Chemistry - Catalysis\n",
        "            \"\"\"\n",
        "            Catalysts are substances that increase the rate of chemical reactions without being\n",
        "            consumed in the process. They work by providing an alternative reaction pathway with\n",
        "            lower activation energy. Enzymes are biological catalysts that are highly specific\n",
        "            for particular reactions.\n",
        "            \"\"\",\n",
        "\n",
        "            # Physics - Mechanics\n",
        "            \"\"\"\n",
        "            Newton's first law of motion states that an object at rest stays at rest and an object\n",
        "            in motion stays in motion with the same speed and in the same direction unless acted\n",
        "            upon by an unbalanced force. This is also known as the law of inertia.\n",
        "            \"\"\",\n",
        "\n",
        "            # Medicine - Pharmacology\n",
        "            \"\"\"\n",
        "            Antibiotics are medicines that fight bacterial infections in people and animals. They work\n",
        "            by killing bacteria or making it difficult for bacteria to grow and multiply. However,\n",
        "            antibiotics do not work against viral infections such as the common cold or flu.\n",
        "            \"\"\",\n",
        "\n",
        "            # Genetics\n",
        "            \"\"\"\n",
        "            DNA replication is a semiconservative process where each strand of the double helix\n",
        "            serves as a template for a new complementary strand. This process is carried out\n",
        "            by DNA polymerase enzymes and occurs during the S phase of the cell cycle.\n",
        "            \"\"\",\n",
        "\n",
        "            # Biochemistry\n",
        "            \"\"\"\n",
        "            Enzymes are protein catalysts that accelerate biochemical reactions by lowering the\n",
        "            activation energy required. The active site of an enzyme binds specifically to\n",
        "            substrate molecules, forming an enzyme-substrate complex that facilitates the reaction.\n",
        "            \"\"\",\n",
        "\n",
        "            # Environmental Science\n",
        "            \"\"\"\n",
        "            The greenhouse effect occurs when certain gases in Earth's atmosphere trap heat\n",
        "            from the sun. Carbon dioxide, methane, and water vapor are the primary greenhouse\n",
        "            gases that contribute to global warming and climate change.\n",
        "            \"\"\",\n",
        "\n",
        "            # Immunology\n",
        "            \"\"\"\n",
        "            Vaccines work by stimulating the immune system to recognize and remember specific\n",
        "            pathogens. They contain antigens that trigger the production of antibodies and\n",
        "            activate memory cells, providing long-term immunity against diseases.\n",
        "            \"\"\",\n",
        "\n",
        "            # Neuroscience\n",
        "            \"\"\"\n",
        "            Neurons communicate through electrical and chemical signals. Action potentials\n",
        "            travel down axons, and at synapses, neurotransmitters are released to transmit\n",
        "            signals to other neurons or target cells.\n",
        "            \"\"\",\n",
        "\n",
        "            # Molecular Biology\n",
        "            \"\"\"\n",
        "            Gene expression involves the transcription of DNA into RNA and the translation\n",
        "            of RNA into proteins. This process is regulated at multiple levels and determines\n",
        "            which genes are active in different cell types and conditions.\n",
        "            \"\"\"\n",
        "        ]\n",
        "\n",
        "        print(\"üß™ Running Comprehensive Evaluation...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for i, context in enumerate(test_contexts, 1):\n",
        "            print(f\"\\nüìù Test {i}/{len(test_contexts)}: {context.strip()[:50]}...\")\n",
        "\n",
        "            try:\n",
        "                # Generate question\n",
        "                start_time = time.time()\n",
        "                question = self.generate_question(context)\n",
        "                generation_time = time.time() - start_time\n",
        "\n",
        "                # Evaluate question\n",
        "                evaluation = self.evaluator.evaluate_single_question(context, question)\n",
        "                evaluation['generation_time'] = generation_time\n",
        "\n",
        "                # Display results\n",
        "                print(f\"‚úÖ Generated Question: {question[:100]}...\")\n",
        "                print(f\"üìä Overall Score: {evaluation['overall_score']:.1f}/100 ({evaluation['quality_rating']})\")\n",
        "                print(f\"‚è±Ô∏è Generation Time: {generation_time:.2f}s\")\n",
        "\n",
        "                results.append(evaluation)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error generating question: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    def display_evaluation_report(self):\n",
        "        \"\"\"Display comprehensive evaluation report\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üìä COMPREHENSIVE EVALUATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Get summary statistics\n",
        "        stats = self.evaluator.get_summary_statistics()\n",
        "\n",
        "        if isinstance(stats, str):\n",
        "            print(stats)\n",
        "            return\n",
        "\n",
        "        # Overall Statistics\n",
        "        print(f\"üìà OVERALL STATISTICS\")\n",
        "        print(f\"   Total Questions Evaluated: {stats['total_questions']}\")\n",
        "        print(f\"   Average Overall Score: {stats['average_scores']['overall']:.1f}/100\")\n",
        "\n",
        "        # Score Breakdown\n",
        "        print(f\"\\nüìä SCORE BREAKDOWN\")\n",
        "        print(f\"   Structure Quality: {stats['average_scores']['structure']:.1f}/100\")\n",
        "        print(f\"   Context Relevance: {stats['average_scores']['relevance']:.1f}/100\")\n",
        "        print(f\"   Scientific Accuracy: {stats['average_scores']['accuracy']:.1f}/100\")\n",
        "\n",
        "        # Quality Distribution\n",
        "        print(f\"\\nüéØ QUALITY DISTRIBUTION\")\n",
        "        for quality, count in stats['quality_distribution'].items():\n",
        "            percentage = (count / stats['total_questions']) * 100\n",
        "            print(f\"   {quality}: {count} questions ({percentage:.1f}%)\")\n",
        "\n",
        "        # Detailed Results\n",
        "        print(f\"\\nüìã DETAILED RESULTS\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(self.evaluator.detailed_results, 1):\n",
        "            print(f\"\\nQuestion {i}:\")\n",
        "            print(f\"   Context: {result['context']}\")\n",
        "            print(f\"   Generated: {result['question'][:100]}...\")\n",
        "            print(f\"   Overall Score: {result['overall_score']:.1f}/100 ({result['quality_rating']})\")\n",
        "            print(f\"   Difficulty: {result['difficulty_level']}\")\n",
        "            print(f\"   Readability: {result['readability']}\")\n",
        "\n",
        "            if result['structure_issues']:\n",
        "                print(f\"   ‚ö†Ô∏è Structure Issues: {', '.join(result['structure_issues'])}\")\n",
        "\n",
        "            if result['accuracy_issues']:\n",
        "                print(f\"   ‚ö†Ô∏è Accuracy Issues: {', '.join(result['accuracy_issues'])}\")\n",
        "\n",
        "        # Recommendations\n",
        "        print(f\"\\nüí° RECOMMENDATIONS\")\n",
        "        avg_overall = stats['average_scores']['overall']\n",
        "\n",
        "        if avg_overall >= 85:\n",
        "            print(\"   üéâ Excellent performance! Your model generates high-quality questions.\")\n",
        "        elif avg_overall >= 70:\n",
        "            print(\"   ‚úÖ Good performance with room for improvement in specific areas.\")\n",
        "        elif avg_overall >= 50:\n",
        "            print(\"   ‚ö†Ô∏è Fair performance. Consider additional training or prompt engineering.\")\n",
        "        else:\n",
        "            print(\"   üîß Performance needs improvement. Review training data and model architecture.\")\n",
        "\n",
        "        # Specific recommendations\n",
        "        if stats['average_scores']['structure'] < 70:\n",
        "            print(\"   ‚Ä¢ Focus on improving question structure and format\")\n",
        "        if stats['average_scores']['relevance'] < 70:\n",
        "            print(\"   ‚Ä¢ Work on maintaining better context relevance\")\n",
        "        if stats['average_scores']['accuracy'] < 70:\n",
        "            print(\"   ‚Ä¢ Improve scientific accuracy and terminology usage\")\n",
        "\n",
        "    def benchmark_performance(self, num_tests=5):\n",
        "        \"\"\"Benchmark generation performance\"\"\"\n",
        "        print(f\"\\n‚è±Ô∏è PERFORMANCE BENCHMARK ({num_tests} runs)\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        test_context = \"\"\"\n",
        "        Mitosis is a type of cell division that results in two daughter cells each having\n",
        "        the same number and kind of chromosomes as the parent nucleus. It is essential\n",
        "        for growth and repair in multicellular organisms.\n",
        "        \"\"\"\n",
        "\n",
        "        times = []\n",
        "        scores = []\n",
        "\n",
        "        for i in range(num_tests):\n",
        "            start_time = time.time()\n",
        "            question = self.generate_question(test_context)\n",
        "            generation_time = time.time() - start_time\n",
        "\n",
        "            evaluation = self.evaluator.evaluate_single_question(test_context, question)\n",
        "\n",
        "            times.append(generation_time)\n",
        "            scores.append(evaluation['overall_score'])\n",
        "\n",
        "            print(f\"   Run {i+1}: {generation_time:.2f}s, Score: {evaluation['overall_score']:.1f}/100\")\n",
        "\n",
        "        print(f\"\\nüìä Performance Summary:\")\n",
        "        print(f\"   Average Generation Time: {np.mean(times):.2f}s\")\n",
        "        print(f\"   Average Quality Score: {np.mean(scores):.1f}/100\")\n",
        "        print(f\"   Consistency (Score StdDev): {np.std(scores):.1f}\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Free up GPU memory\"\"\"\n",
        "        del self.model\n",
        "        del self.tokenizer\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"üßπ Memory cleaned up!\")\n",
        "\n",
        "# Main evaluation functions\n",
        "def run_full_evaluation(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Run complete evaluation suite\"\"\"\n",
        "    print(\"üéØ QA Generator Comprehensive Evaluation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = QAGeneratorEvaluator(adapter_path)\n",
        "\n",
        "    # Run comprehensive evaluation\n",
        "    results = evaluator.evaluate_comprehensive_test()\n",
        "\n",
        "    # Display detailed report\n",
        "    evaluator.display_evaluation_report()\n",
        "\n",
        "    # Run performance benchmark\n",
        "    evaluator.benchmark_performance(3)\n",
        "\n",
        "    # Cleanup\n",
        "    evaluator.cleanup()\n",
        "\n",
        "    return results\n",
        "\n",
        "def quick_evaluation(adapter_path=\"./qa_adapter\"):\n",
        "    \"\"\"Quick evaluation with fewer test cases\"\"\"\n",
        "    print(\"‚ö° Quick Evaluation Mode\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    evaluator = QAGeneratorEvaluator(adapter_path)\n",
        "\n",
        "    # Test with 3 contexts only\n",
        "    quick_contexts = [\n",
        "        \"\"\"\n",
        "        Photosynthesis is the process by which plants convert light energy into chemical energy.\n",
        "        During this process, carbon dioxide and water are converted into glucose and oxygen\n",
        "        using energy from sunlight.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        DNA replication is a semiconservative process where each strand serves as a template\n",
        "        for a new complementary strand. This occurs during the S phase of the cell cycle.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Antibiotics fight bacterial infections by killing bacteria or preventing their growth.\n",
        "        However, they are ineffective against viral infections.\n",
        "        \"\"\"\n",
        "    ]\n",
        "\n",
        "    for i, context in enumerate(quick_contexts, 1):\n",
        "        print(f\"\\nüìù Quick Test {i}:\")\n",
        "        question = evaluator.generate_question(context)\n",
        "        evaluation = evaluator.evaluator.evaluate_single_question(context, question)\n",
        "        print(f\"   Score: {evaluation['overall_score']:.1f}/100 ({evaluation['quality_rating']})\")\n",
        "        print(f\"   Question: {question[:80]}...\")\n",
        "\n",
        "    evaluator.cleanup()\n",
        "    return evaluator.evaluator.detailed_results\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üéØ QA Generator Evaluation System\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    choice = input(\"Choose evaluation mode:\\n1. Full evaluation (10 contexts)\\n2. Quick evaluation (3 contexts)\\nEnter choice (1/2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        run_full_evaluation(\"./qa_adapter\")\n",
        "    else:\n",
        "        quick_evaluation(\"./qa_adapter\")\n",
        "\n",
        "    print(\"\\n‚úÖ Evaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQYFTsxHbEy1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00d66d35cd254b7db98101bf637ffce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783fd5f9e0d34590af17adac73659370",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b715f7dc07bf42f683d21ee1a3d5a5de",
            "value": 2
          }
        },
        "03a39a3a8ba748458b3497462579e477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949b0a01f54e43a2a33f16ace68ba63a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba12d5e58ac14494baccf7b456082bd9",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "06c7856220f745c6b1796d71227882c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d517f8043b148f2bd3d5950dc80c946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bda4596e37c04c21a678cda292d637e2",
              "IPY_MODEL_25f220c3e53746e7b0bd16696e9d8b62",
              "IPY_MODEL_630d56bd42d44f42ad1f5f095f127134"
            ],
            "layout": "IPY_MODEL_2c26a737d6ca43feb88214d30da65c59"
          }
        },
        "0ecb7806bb08455ab41f6206147107c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115edd570640483b94f3623707e6dff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1490ec9b6d3e49729ababf4f8739a72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a485cab7043d46858fa60f6aff28cc14",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663ca508975c4310925a4c6cdc44a661",
            "value": 2
          }
        },
        "14a248b3132344ef8d0faa2423b61648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b914549f08a648c69d1536dd4c43b41e",
              "IPY_MODEL_14f0b15eac474d52ae18a28b449d1824",
              "IPY_MODEL_8de6b6f1f8c44dcdbabf4044ead2cdc6"
            ],
            "layout": "IPY_MODEL_55c469002fe14c7bba14a4571fae8c45"
          }
        },
        "14a900a1d3184631960a2d4b01146186": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f0b15eac474d52ae18a28b449d1824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe17b73ab9c45c3a861b8239d75b25d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ade09eaf0bd414983365a4d81b630fc",
            "value": 2
          }
        },
        "198540889a5a4a7db55ef7227306567f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c69587c0b624aaebd05aaabbbeb92e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6a3776c7204a9ca876aead451aa85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ffbd396dc0e43929bc62d7987c46e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20cb6a5b52094396a0bbb7600c514212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3dcf659176403fae3d3c7d316337a0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ce82056d330646d99deb461345e18fc7",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "233696c261e147ecae7a927bf149d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8377e2a71204448290a5fc7bf60c9b43",
            "max": 4972489328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c6a3776c7204a9ca876aead451aa85b",
            "value": 4972489328
          }
        },
        "23522d8efbb8467d8a5343e44d81c778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8026095f28ed453db681ca6b5a3e6004",
              "IPY_MODEL_00d66d35cd254b7db98101bf637ffce8",
              "IPY_MODEL_61ccc0ee45474932b0638719a3c02139"
            ],
            "layout": "IPY_MODEL_45da3481df8e4ec3abea2a98820b3fcc"
          }
        },
        "2570235c9a884840bc1345c3922835f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c09c55fbe2475999305c494a9e5f86",
              "IPY_MODEL_d5969279042d45fab6c8dfbf87202cf4",
              "IPY_MODEL_5e2491325bfd4179a2a81840c453fb48"
            ],
            "layout": "IPY_MODEL_6991bf455dc84fd5bba5369f000f78e0"
          }
        },
        "25f220c3e53746e7b0bd16696e9d8b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb2ee2abbe04334afb2ae2a9173c4a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad88bf875792445ca477093e1db8ccdc",
            "value": 1
          }
        },
        "2916799eb9314ceab9e71ed210d57f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9649b128bd3d4c6b9635f20867df7fe1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06c7856220f745c6b1796d71227882c2",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "2c0c7e57edc94a3583cb2a86ec26b07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c26a737d6ca43feb88214d30da65c59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c50c4db4c34135af08f58cfebf6dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357fdca8035b4a0691b35552029ff3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3798554d15f744e1bf60c61a42e3d4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e6c9ccdf954aa3bb99b1d1fcf17e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c50c4db4c34135af08f58cfebf6dfc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8c69cb7465e441c9a592d2c6cf7428a",
            "value": 2
          }
        },
        "3d8349737b744266afbf8e850a6d21ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df5fddc48764fd1bad393616d6d606a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "451660d2ba1e4b1fa592acfb14b8471c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd964c8bcfd946fda06506d3b33d032c",
              "IPY_MODEL_233696c261e147ecae7a927bf149d551",
              "IPY_MODEL_cc1801f7329245659141d66e838b66e4"
            ],
            "layout": "IPY_MODEL_4e78a6457b94498986253dd19a3b309d"
          }
        },
        "4596a4bd71ee4939bc907a2ffc099f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45da3481df8e4ec3abea2a98820b3fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a75c000baba4409a82d95ee97a8fa17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecb7806bb08455ab41f6206147107c6",
            "max": 2669692552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c0c7e57edc94a3583cb2a86ec26b07b",
            "value": 2669692552
          }
        },
        "4b77f8a1e1ee40a7833cf13744de682a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3dcf659176403fae3d3c7d316337a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e78a6457b94498986253dd19a3b309d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d864059afb4af58d40ad07051770d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c469002fe14c7bba14a4571fae8c45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566284d195c040a9aaf1021386df8995": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59160750ef8d4288bbbe7c7fcf5bb03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59ae9fd7e1a7410292e364953df46549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d707f2b057442ef901bc3da92fdbe04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2491325bfd4179a2a81840c453fb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b77f8a1e1ee40a7833cf13744de682a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e4a6560f9d5a45deb91aecc3835253f3",
            "value": "‚Äá2/2‚Äá[00:45&lt;00:00,‚Äá21.72s/it]"
          }
        },
        "61ccc0ee45474932b0638719a3c02139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df5fddc48764fd1bad393616d6d606a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1ffbd396dc0e43929bc62d7987c46e74",
            "value": "‚Äá2/2‚Äá[03:14&lt;00:00,‚Äá194.82s/it]"
          }
        },
        "630d56bd42d44f42ad1f5f095f127134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a900a1d3184631960a2d4b01146186",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d61c3c9d668c428c9688f050e31b0c71",
            "value": "‚Äá16.5k/?‚Äá[00:00&lt;00:00,‚Äá798kB/s]"
          }
        },
        "64cd0a1737a44c848284a71cb8a1d7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ee94d5a7954fe287320a0171958995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20cb6a5b52094396a0bbb7600c514212",
              "IPY_MODEL_1490ec9b6d3e49729ababf4f8739a72f",
              "IPY_MODEL_bf05f7f9b67a4923930331b7d1fc4d18"
            ],
            "layout": "IPY_MODEL_cd81a28e38d04d7b80bc67d86f2b7f43"
          }
        },
        "663ca508975c4310925a4c6cdc44a661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6991bf455dc84fd5bba5369f000f78e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a065a5dd9f944379b762d6f61f451b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba02fb49e024339b353c4bfa60c4c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ce804418e04a76b0603145b0efc2c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7f81fc8579684b209ea5253a895f3bdb",
            "value": "‚Äá181/181‚Äá[00:00&lt;00:00,‚Äá21.5kB/s]"
          }
        },
        "742a4cf56eb34cb98ef1c46e5bc8de67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "783fd5f9e0d34590af17adac73659370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ade09eaf0bd414983365a4d81b630fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f359a1daafc4e1c98e3cdd10d0be765": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f81fc8579684b209ea5253a895f3bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8026095f28ed453db681ca6b5a3e6004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357fdca8035b4a0691b35552029ff3ba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4596a4bd71ee4939bc907a2ffc099f0f",
            "value": "Fetching‚Äá2‚Äáfiles:‚Äá100%"
          }
        },
        "8377e2a71204448290a5fc7bf60c9b43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855902b5c55047389f37c1ec9b5fac57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f359a1daafc4e1c98e3cdd10d0be765",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d008e5dc094444f68c23b9c028bf4610",
            "value": "‚Äá2.67G/2.67G‚Äá[02:57&lt;00:00,‚Äá5.73MB/s]"
          }
        },
        "88fccea2fc5c4d059697a9d963ae4a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2916799eb9314ceab9e71ed210d57f7a",
              "IPY_MODEL_95040c8eca004027b215d39f0c5b2a8f",
              "IPY_MODEL_ece6f3330af745ed85473bea9416598e"
            ],
            "layout": "IPY_MODEL_f6827e0779a44f75b606d0abae3b2673"
          }
        },
        "8b3a61cb55c240569f2f6a376a97476d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de6b6f1f8c44dcdbabf4044ead2cdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b551b38d0461487595126e8bdbb3d98e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_198540889a5a4a7db55ef7227306567f",
            "value": "‚Äá2/2‚Äá[00:33&lt;00:00,‚Äá15.86s/it]"
          }
        },
        "8fecfa739c844e4f82f095e6daa948f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c9a85f56444d69b0dd48bd572d9e30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949b0a01f54e43a2a33f16ace68ba63a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95040c8eca004027b215d39f0c5b2a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fecfa739c844e4f82f095e6daa948f2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59160750ef8d4288bbbe7c7fcf5bb03c",
            "value": 2
          }
        },
        "9649b128bd3d4c6b9635f20867df7fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b6c764f92444d48c2fde0fa0c9746d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab23decda9642cdbb906896582b853b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a40545f45b9344ee9ee3906d2dada0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3798554d15f744e1bf60c61a42e3d4b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3d8349737b744266afbf8e850a6d21ff",
            "value": "model-00002-of-00002.safetensors:‚Äá100%"
          }
        },
        "a485cab7043d46858fa60f6aff28cc14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5750dc15a0e498d9737738d88a9ec34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ce804418e04a76b0603145b0efc2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa85516d59e14b5db849fa58003b794a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a39a3a8ba748458b3497462579e477",
              "IPY_MODEL_c45b9f6b58384adfbe14e3033c26f31d",
              "IPY_MODEL_6ba02fb49e024339b353c4bfa60c4c66"
            ],
            "layout": "IPY_MODEL_1c69587c0b624aaebd05aaabbbeb92e6"
          }
        },
        "abec8059707f4e08b376860290405b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbe17b52d6604ee8820a0d4ad3ce8166",
              "IPY_MODEL_38e6c9ccdf954aa3bb99b1d1fcf17e3b",
              "IPY_MODEL_e40fa8b771e4455588210942f0dbdc98"
            ],
            "layout": "IPY_MODEL_c235d35a07d448d69e1a563e168b7e5a"
          }
        },
        "ad88bf875792445ca477093e1db8ccdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af510f19364a4be4acaa83f26cf390e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afedd9773fa441c68345adf6811b8091": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b551b38d0461487595126e8bdbb3d98e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b715f7dc07bf42f683d21ee1a3d5a5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b914549f08a648c69d1536dd4c43b41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd6a5133fec4493992edb587ef7fb81",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a5750dc15a0e498d9737738d88a9ec34",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "ba12d5e58ac14494baccf7b456082bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd964c8bcfd946fda06506d3b33d032c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7144f441e8a4b47b5c76f53d294ad4a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_742a4cf56eb34cb98ef1c46e5bc8de67",
            "value": "model-00001-of-00002.safetensors:‚Äá100%"
          }
        },
        "bda4596e37c04c21a678cda292d637e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77b67394cfb4c0a9fbcd3114e606a8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c31252560d3c48dd8f59c3576c373688",
            "value": "model.safetensors.index.json:‚Äá"
          }
        },
        "bf05f7f9b67a4923930331b7d1fc4d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566284d195c040a9aaf1021386df8995",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d2a858f323664438b70a513d5414d0a5",
            "value": "‚Äá2/2‚Äá[00:53&lt;00:00,‚Äá24.92s/it]"
          }
        },
        "c235d35a07d448d69e1a563e168b7e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31252560d3c48dd8f59c3576c373688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c45b9f6b58384adfbe14e3033c26f31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b3a61cb55c240569f2f6a376a97476d",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ab23decda9642cdbb906896582b853b",
            "value": 181
          }
        },
        "c8c69cb7465e441c9a592d2c6cf7428a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbabc9ef93ca4c148e8645b1d69771bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe17b52d6604ee8820a0d4ad3ce8166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c9a85f56444d69b0dd48bd572d9e30",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cbabc9ef93ca4c148e8645b1d69771bd",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "cc1801f7329245659141d66e838b66e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afedd9773fa441c68345adf6811b8091",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_50d864059afb4af58d40ad07051770d8",
            "value": "‚Äá4.97G/4.97G‚Äá[03:14&lt;00:00,‚Äá40.3MB/s]"
          }
        },
        "cc86e9b1134645e5878de82698b5adae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb2ee2abbe04334afb2ae2a9173c4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cd81a28e38d04d7b80bc67d86f2b7f43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce82056d330646d99deb461345e18fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d008e5dc094444f68c23b9c028bf4610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2a858f323664438b70a513d5414d0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ab2131b87c4216a924994dee4c9429": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a40545f45b9344ee9ee3906d2dada0fc",
              "IPY_MODEL_4a75c000baba4409a82d95ee97a8fa17",
              "IPY_MODEL_855902b5c55047389f37c1ec9b5fac57"
            ],
            "layout": "IPY_MODEL_e63f066a983e4a74b82b22fbfcca43da"
          }
        },
        "d3c09c55fbe2475999305c494a9e5f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc86e9b1134645e5878de82698b5adae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a065a5dd9f944379b762d6f61f451b0",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d5969279042d45fab6c8dfbf87202cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cd0a1737a44c848284a71cb8a1d7ea",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_115edd570640483b94f3623707e6dff3",
            "value": 2
          }
        },
        "d61c3c9d668c428c9688f050e31b0c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd6a5133fec4493992edb587ef7fb81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe17b73ab9c45c3a861b8239d75b25d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40fa8b771e4455588210942f0dbdc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af510f19364a4be4acaa83f26cf390e8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_98b6c764f92444d48c2fde0fa0c9746d",
            "value": "‚Äá2/2‚Äá[00:38&lt;00:00,‚Äá18.31s/it]"
          }
        },
        "e4a6560f9d5a45deb91aecc3835253f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63f066a983e4a74b82b22fbfcca43da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7144f441e8a4b47b5c76f53d294ad4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e77b67394cfb4c0a9fbcd3114e606a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece6f3330af745ed85473bea9416598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d707f2b057442ef901bc3da92fdbe04",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_59ae9fd7e1a7410292e364953df46549",
            "value": "‚Äá2/2‚Äá[00:37&lt;00:00,‚Äá17.91s/it]"
          }
        },
        "f6827e0779a44f75b606d0abae3b2673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
